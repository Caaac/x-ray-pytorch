{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b762cf0f",
   "metadata": {},
   "source": [
    "### Анализ рентгеновских снимков по картинкам с прогнозированием заболеваний\n",
    "\n",
    "#### [Ссылка на датасет](https://huggingface.co/datasets/Sohaibsoussi/NIH-Chest-X-ray-dataset-small)\n",
    "\n",
    "```\n",
    "class_label:\n",
    "  '0': No Finding\n",
    "  '1': Atelectasis\n",
    "  '2': Cardiomegaly\n",
    "  '3': Effusion\n",
    "  '4': Infiltration\n",
    "  '5': Mass\n",
    "  '6': Nodule\n",
    "  '7': Pneumonia\n",
    "  '8': Pneumothorax\n",
    "  '9': Consolidation\n",
    "  '10': Edema\n",
    "  '11': Emphysema\n",
    "  '12': Fibrosis\n",
    "  '13': Pleural_Thickening\n",
    "  '14': Hernia\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5328b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !source venv/bin/activate  \n",
    "# !pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "195e0b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms.v2 as tfs_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a9fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR_PATH = os.path.abspath(os.path.curdir)\n",
    "DATASET_DIR_PATH = os.path.join(PROJECT_DIR_PATH, 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a4174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XRayDataset(data.Dataset):\n",
    "    def __init__(self, path: str, type_file: str, transform=None):\n",
    "        self.path = path\n",
    "        self.type_file = type_file\n",
    "        self.transform = transform\n",
    "\n",
    "        self.length = 0\n",
    "        # self.files = []\n",
    "        # self.targets = []\n",
    "        self.classes = torch.eye(15)\n",
    "\n",
    "        not_split_data = self.get_unpack_img()\n",
    "        files, targets, _length = self.split_data(not_split_data)\n",
    "\n",
    "        self.df = pd.DataFrame({'path': files, 'target': targets})\n",
    "        self.length = self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        file_path, target = self.df.iloc[index]\n",
    "        img = Image.open(file_path).convert('RGB')\n",
    "        \n",
    "        if (self.transform is not None):\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, self.classes[target]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def get_unpack_img(self) -> list:\n",
    "        type_file_path = os.path.join(self.path, self.type_file)\n",
    "\n",
    "        if os.path.exists(type_file_path):\n",
    "            shutil.rmtree(type_file_path)\n",
    "\n",
    "        os.makedirs(type_file_path, exist_ok=True)\n",
    "\n",
    "        parquet_files = [f for f in os.listdir(self.path) if f.startswith(\n",
    "            self.type_file) and f.endswith('.parquet')]\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for file_name in tqdm(parquet_files, desc=f\"Unpacking {self.type_file}\"):\n",
    "            df = pd.read_parquet(os.path.join(self.path, file_name))\n",
    "\n",
    "            for idx, row in df.iterrows():\n",
    "                img_path = os.path.join(type_file_path, f\"image_{idx}.png\")\n",
    "\n",
    "                if isinstance(row['image']['bytes'], bytes):\n",
    "                    with open(img_path, 'wb') as f:\n",
    "                        f.write(row['image']['bytes'])\n",
    "                # else:\n",
    "                #     img = Image.fromarray(row['image'])\n",
    "                #     img.save(img_path)\n",
    "\n",
    "                result.append((img_path, row['labels']))\n",
    "\n",
    "        return result\n",
    "\n",
    "    def split_data(self, not_split_data: list):\n",
    "        files = []\n",
    "        targets = []\n",
    "        length = 0\n",
    "\n",
    "        for path, labels in not_split_data:\n",
    "            for target in labels.tolist():\n",
    "                files.append(path)\n",
    "                targets.append(int(target))\n",
    "                length += 1\n",
    "\n",
    "        return files, targets, length\n",
    "\n",
    "    def cut_dataframe(self, target: str | int, count: int) -> None:\n",
    "        rows_to_drop = self.df[self.df['target'] == target].index[:count]\n",
    "        self.df = self.df.drop(rows_to_drop)\n",
    "        self.length = self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d673d278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unpacking test: 100%|██████████| 2/2 [00:01<00:00,  1.68it/s]\n",
      "Unpacking train: 100%|██████████| 4/4 [00:03<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "d_test = XRayDataset(DATASET_DIR_PATH, 'test')\n",
    "d_train = XRayDataset(DATASET_DIR_PATH, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8f4007a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATASET\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5260 entries, 0 to 5259\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   path    5260 non-null   object\n",
      " 1   target  5260 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 82.3+ KB\n",
      "None\n",
      "\n",
      "target\n",
      "0     2489\n",
      "4      685\n",
      "3      459\n",
      "1      431\n",
      "6      243\n",
      "5      194\n",
      "9      165\n",
      "8      144\n",
      "13     108\n",
      "2       77\n",
      "12      75\n",
      "11      71\n",
      "10      61\n",
      "7       43\n",
      "14      15\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('TRAIN_DATASET')\n",
    "print(d_train.df.info(), end='\\n\\n')\n",
    "print(d_train.df.target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06b28582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_DATASET\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1828 entries, 0 to 1827\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   path    1828 non-null   object\n",
      " 1   target  1828 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 28.7+ KB\n",
      "None\n",
      "\n",
      "target\n",
      "0     541\n",
      "4     284\n",
      "3     213\n",
      "1     160\n",
      "8     146\n",
      "5      96\n",
      "9      77\n",
      "6      73\n",
      "11     60\n",
      "13     55\n",
      "2      42\n",
      "10     31\n",
      "12     26\n",
      "7      23\n",
      "14      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('TEST_DATASET')\n",
    "print(d_test.df.info(), end='\\n\\n')\n",
    "print(d_test.df.target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "387ccdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0     1189\n",
       "4      685\n",
       "3      459\n",
       "1      431\n",
       "6      243\n",
       "5      194\n",
       "9      165\n",
       "8      144\n",
       "13     108\n",
       "2       77\n",
       "12      75\n",
       "11      71\n",
       "10      61\n",
       "7       43\n",
       "14      15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train.cut_dataframe(0, 1300)\n",
    "d_train.df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e5b7a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Dev/DS/x-ray-pytorch/venv/lib/python3.13/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transform = tfs_v2.Compose([\n",
    "    tfs_v2.ToTensor(),\n",
    "    tfs_v2.ToDtype(dtype=torch.float32, scale=True),\n",
    "    tfs_v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                     std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "d_train.transform = transform\n",
    "train_data = data.DataLoader(d_train, batch_size=4, shuffle=True)\n",
    "\n",
    "model = models.vgg16(weights='IMAGENET1K_V1')\n",
    "\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(25088, 4096), # 512*7*7 = 25088\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4096, 15) \n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "# loss_function = nn.BCEWithLogitsLoss()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1237a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "modal_start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "os.makedirs(os.path.join(PROJECT_DIR_PATH, 'models',\n",
    "            'vgg16', modal_start_time), exist_ok=True)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for _e in range(epochs):\n",
    "    loss_mean = 0  # среднее значение функции потерь (по эпохе)\n",
    "    lm_count = 0  # текущее количество слагаемых\n",
    "\n",
    "    train_tqdm = tqdm(train_data, leave=True)\n",
    "\n",
    "    for x_train, y_train in train_tqdm:\n",
    "        x_train = x_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "\n",
    "        y_pred = model(x_train)\n",
    "        loss = loss_function(y_pred, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        lm_count += 1\n",
    "        loss_mean = 1/lm_count * loss.item() + (1 - 1/lm_count) * loss_mean\n",
    "        train_tqdm.set_description(\n",
    "            f\"Epoch [{_e+1}/{epochs}], loss_mean={loss_mean:.3f}\")\n",
    "\n",
    "    model_state_dict = {\n",
    "        'tfs': transform.state_dict(),\n",
    "        'opt': optimizer.state_dict(),\n",
    "        'model': model.state_dict(),\n",
    "    }\n",
    "\n",
    "    torch.save(model_state_dict,\n",
    "               f\"./models/vgg16/{modal_start_time}/epoch_{_e + 1}.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625d827",
   "metadata": {},
   "source": [
    "```py\n",
    "# weights_only=True означает, что выполняется загрузка примитивных типов данных, например: словарей, тензоров, списков, строк и т.п. \n",
    "model_data = torch.load('model_name.tar', weights_only=True)\n",
    "model.load_state_dict(model_data['model'])\n",
    "transforms.load_state_dict(model_data['tfs'])\n",
    "optimizer.load_state_dict(model_data['opt'])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5ffa7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unpacking validation: 100%|██████████| 2/2 [00:00<00:00,  2.27it/s]\n"
     ]
    }
   ],
   "source": [
    "d_valid = XRayDataset(DATASET_DIR_PATH, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e166f9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2079 entries, 0 to 2078\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   path    2079 non-null   object\n",
      " 1   target  2079 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 32.6+ KB\n",
      "None\n",
      "\n",
      "target\n",
      "0     995\n",
      "4     292\n",
      "1     177\n",
      "3     168\n",
      "6      87\n",
      "5      72\n",
      "9      59\n",
      "8      52\n",
      "13     50\n",
      "2      30\n",
      "12     30\n",
      "11     26\n",
      "10     18\n",
      "7      16\n",
      "14      7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(d_valid.df.info(), end=\"\\n\\n\")\n",
    "print(d_valid.df.target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f671edad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Dev/DS/x-ray-pytorch/venv/lib/python3.13/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transform = tfs_v2.Compose([\n",
    "    tfs_v2.ToTensor(),\n",
    "    tfs_v2.ToDtype(dtype=torch.float32, scale=True),\n",
    "    tfs_v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                     std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "d_valid.transform = transform\n",
    "valid_data = data.DataLoader(dataset=d_valid, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "model = models.vgg16(weights='IMAGENET1K_V1')\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(25088, 4096),  # 512*7*7 = 25088\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4096, 15)\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "# loss_function = nn.BCEWithLogitsLoss()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402effe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = torch.load('./models/vgg16/2025-05-06 06:41:01/epoch_4.tar', map_location=device, weights_only=True)\n",
    "\n",
    "model.load_state_dict(model_data['model'])\n",
    "optimizer.load_state_dict(model_data['opt'])\n",
    "transform.load_state_dict(model_data['tfs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129cb4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    valid_tqdm = tqdm(valid_data, leave=True)\n",
    "    \n",
    "    for x_valid, y_valid in valid_tqdm:\n",
    "        x_valid = x_valid.to(device)\n",
    "        y_valid = y_valid.to(device)\n",
    "        \n",
    "\n",
    "        y_pred = model(x_valid)\n",
    "        \n",
    "        print(y_valid[0])\n",
    "        print(y_pred[0])\n",
    "        \n",
    "        break\n",
    "    \n",
    "\n",
    "\t\t\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b762cf0f",
   "metadata": {},
   "source": [
    "### Анализ рентгеновских снимков по картинкам с прогнозированием заболеваний\n",
    "\n",
    "#### [Ссылка на датасет](https://huggingface.co/datasets/Sohaibsoussi/NIH-Chest-X-ray-dataset-small)\n",
    "\n",
    "```\n",
    "class_label:\n",
    "  '0': No Finding\n",
    "  '1': Atelectasis\n",
    "  '2': Cardiomegaly\n",
    "  '3': Effusion\n",
    "  '4': Infiltration\n",
    "  '5': Mass\n",
    "  '6': Nodule\n",
    "  '7': Pneumonia\n",
    "  '8': Pneumothorax\n",
    "  '9': Consolidation\n",
    "  '10': Edema\n",
    "  '11': Emphysema\n",
    "  '12': Fibrosis\n",
    "  '13': Pleural_Thickening\n",
    "  '14': Hernia\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "195e0b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms.v2 as tfs_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "44a9fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR_PATH = os.path.abspath(os.path.curdir)\n",
    "DATASET_DIR_PATH = os.path.join(PROJECT_DIR_PATH, 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "99a4174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XRayDataset(data.Dataset):\n",
    "    def __init__(self, path: str, type_file: str = True, transform=None):\n",
    "        self.path = path\n",
    "        self.type_file = type_file\n",
    "        self.transform = transform\n",
    "\n",
    "        self.length = 0\n",
    "        self.files = []\n",
    "        self.targets = []\n",
    "        \n",
    "        not_split_data = self.get_unpack_img()\n",
    "        self.files, self.targets, self.length = self.split_data(not_split_data)\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "            file_path = self.files[index]\n",
    "            target = self.targets[index]\n",
    "            \n",
    "            return file_path, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "        \n",
    "    def get_unpack_img(self) -> list:\n",
    "        type_file_path = os.path.join(self.path, self.type_file)\n",
    "\n",
    "        if os.path.exists(type_file_path):\n",
    "            shutil.rmtree(type_file_path)\n",
    "\n",
    "        os.makedirs(type_file_path, exist_ok=True)\n",
    "\n",
    "        parquet_files = [f for f in os.listdir(self.path) if f.startswith(self.type_file) and f.endswith('.parquet')]\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for file_name in parquet_files:\n",
    "            df = pd.read_parquet(os.path.join(self.path, file_name))\n",
    "            \n",
    "            for idx, row in df.iterrows():\n",
    "                img_path = os.path.join(type_file_path, f\"image_{idx}.png\")\n",
    "                \n",
    "                if isinstance(row['image']['bytes'], bytes):\n",
    "                    with open(img_path, 'wb') as f:\n",
    "                        f.write(row['image']['bytes'])\n",
    "                # else:\n",
    "                #     img = Image.fromarray(row['image'])\n",
    "                #     img.save(img_path)\n",
    "                \n",
    "                result.append((img_path, row['labels']))\n",
    "                \n",
    "        return result\n",
    "\n",
    "    def split_data(self, not_split_data):\n",
    "        files = []\n",
    "        targets = []\n",
    "        length = 0\n",
    "        \n",
    "        for path, labels in not_split_data:\n",
    "            for target in labels.tolist():\n",
    "                files.append(path)\n",
    "                targets.append(target)\n",
    "                length += 1\n",
    "        \n",
    "        return files, targets, length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "214b4bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tarin = XRayDataset(DATASET_DIR_PATH, 'train')\n",
    "d_test = XRayDataset(DATASET_DIR_PATH, 'test')\n",
    "d_valid = XRayDataset(DATASET_DIR_PATH, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "7bb84808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.XRayDataset object at 0x17fb75e80>\n"
     ]
    }
   ],
   "source": [
    "print(d_tarin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "79a3b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unpack_img(type_file) -> None:\n",
    "#     type_file_path = os.path.join(DATASET_DIR_PATH, type_file)\n",
    "    \n",
    "#     if os.path.exists(type_file_path):\n",
    "#         shutil.rmtree(type_file_path)\n",
    "        \n",
    "#     os.makedirs(type_file_path, exist_ok=True)\n",
    "\n",
    "#     parquet_files = [f for f in os.listdir(DATASET_DIR_PATH) if f.startswith(type_file) and f.endswith('.parquet')]\n",
    "    \n",
    "#     for file_name in parquet_files:\n",
    "#         df = pd.read_parquet(os.path.join(DATASET_DIR_PATH, file_name))\n",
    "        \n",
    "#         for idx, row in df.iterrows():\n",
    "#             img_path = os.path.join(type_file_path, f\"image_{idx}.png\")\n",
    "            \n",
    "#             if isinstance(row['image']['bytes'], bytes):\n",
    "#                 with open(img_path, 'wb') as f:\n",
    "#                     f.write(row['image']['bytes'])\n",
    "#             # else:\n",
    "#             #     img = Image.fromarray(row['image'])\n",
    "#             #     img.save(img_path)\n",
    "            \n",
    "#             # paths.append(img_path)\n",
    "#             # classes.append(row['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "895a8059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if unpack:\n",
    "#     unpack_img('test')\n",
    "#     unpack_img('train')\n",
    "\n",
    "# print(len(os.listdir(os.path.join(DATASET_DIR_PATH, 'train'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "1cd51966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image labels\n",
       "0  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...    [0]\n",
       "1  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...    [1]\n",
       "2  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...    [1]\n",
       "3  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...    [0]\n",
       "4  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...    [0]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(os.path.join(DATASET_DIR_PATH, DATASET_TEST_FILES[0]))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "3bd695e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "python_list = np.array([1, 2, 3], dtype=np.int64)\n",
    "\n",
    "python_list.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
